{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Plummer Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax._src.config import config\n",
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# use my stylesheet\n",
    "plt.style.use('/Users/juan/phd/matplotlib/jdefault.mplstyle') # this should be changed something in the repo\n",
    "\n",
    "#sampling and inference\n",
    "import numpyro\n",
    "from numpyro.diagnostics import hpdi\n",
    "import numpyro.distributions as dist\n",
    "from numpyro import handlers\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "#need to get rid of\n",
    "import numpy as np\n",
    "\n",
    "# project\n",
    "from dynamicAll import models,fit,data\n",
    "from dynamicAll.fit import Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'M' : 1e5,\n",
    "    'a': 0.5\n",
    "}\n",
    "model = models.Plummer(**model_params)\n",
    "samples= model.sample_w_conditional(N=10_000,save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.sqrt(samples[:,0]**2 + samples[:,1]**2 + samples[:,2]**2)\n",
    "v = np.sqrt(samples[:,3]**2 + samples[:,4]**2 + samples[:,5]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      2\u001b[0m r_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      3\u001b[0m N, bin_edges \u001b[38;5;241m=\u001b[39m histogram(r, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig,ax = plt.subplots(ncols=2,figsize=(14,5))\n",
    "r_test = np.logspace(-2,2,100)\n",
    "N,bin_edges = histogram(r,bins='blocks')\n",
    "r_center = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "q = v/model.v_esc(r)\n",
    "# sanity checks\n",
    "N,vel_edges = histogram(q,bins='blocks')\n",
    "q_test = np.logspace(-2,0,100)\n",
    "\n",
    "\n",
    "ax[0].hist(r,bins=bin_edges,density='True',label='sampling')\n",
    "ax[0].plot(r_test,model.probability(r_test),label='Analytical')\n",
    "ax[0].set(\n",
    "    xscale = 'log',\n",
    "    xlabel = 'r pkpc',\n",
    "    ylabel =r'$pdf(r)$' \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "ax[1].hist(q,bins=vel_edges,density=True);\n",
    "ax[1].plot(q_test,g_q(q_test))\n",
    "ax[1].set(\n",
    "    xscale='log',\n",
    "    ylim = (0,3),\n",
    "    xlabel=r'$q =\\frac{v}{v_{esc}}(r)$',\n",
    "    ylabel=r'$pdf(q)$'\n",
    ")\n",
    "ax[0].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data from a Plummer sphere.\n",
    "\n",
    "This one is quite simple and there are many examples of sampling from a plummer sphere, but lets go over it anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plummer sphere is defined by the density profile\n",
    "\\begin{equation}\n",
    "\\rho(r) = \\frac{3M}{4\\pi a^3}\\left(1 + \\frac{r^2}{a^2}\\right)^{-5/2}\n",
    "\\end{equation}\n",
    "\n",
    "For various systems, we'll have to numerically calculate the distribution function via the Eddington formula, but we'll start with the Plummer sphere where you can derive it analytically.\n",
    "(See B&T for a derivation)\n",
    "\n",
    "The distribution function for a Plummer sphere is given by\n",
    "\n",
    "\\begin{equation}\n",
    "f(E) =\n",
    "\\frac{24\\sqrt{2}}{7\\pi^3}\n",
    "\\frac{a^2}{G^5 M^4}(-E)^{7/2}\n",
    "\\end{equation}\n",
    "\n",
    "Where M is the total mass of the system, and a is the Plummer radius, and $E=\\Phi(r) + \\frac{1}{2}v^2$ is the energy of a particle and goes from $\\Phi(r = 0) = -\\frac{GM}{a}$ to 0. \n",
    "\n",
    "\n",
    "For the purposes of making mock data of a plummer sphere it is useful to remember that the distribution function is the joint probabilty of finding a star in the phase-space volume $d^{3}\\vec{x}d^{3}\\vec{w}$ around the position $\\vec{x}$ and velocity $\\vec{w}$, and that the density is the marginal probability of finding a star in the volume $d^{3}\\vec{x}$ around the position $\\vec{x}$.\n",
    "\n",
    "We can therefore write the conditional probability of finding a star in the volume $d^{3}\\vec{v}$ around the velocity $\\vec{v}$ given that it is at position $\\vec{x}$ using Bayes' theorem as\n",
    "\\begin{equation}\n",
    "P(\\vec{v}|\\vec{x}) = \\frac{P(\\vec{x},\\vec{v})}{P(\\vec{x})} = \\frac{f(E)}{\\rho(\\vec{x})}\n",
    "\\end{equation}\n",
    "\n",
    "However, none of this is particularly useful, until we start rewriting some stuff.\n",
    "\\begin{equation}\n",
    "F(E) = f(\\vec{x},\\vec{v})\n",
    "\\end{equation}\n",
    "but because everything is spherical and Isotropic we can instead write down \n",
    "\\begin{equation}\n",
    "f(r,v)\\sim v^{2}r^{2}\\left[-\\left(\\Phi(r)+\\frac{1}{2}v^{2}\\right)\\right]^{7/2}\n",
    "\\end{equation}\n",
    "\n",
    "and also\n",
    "\\begin{equation}\n",
    "p(r) = 4\\pi r^{2}\\rho(r)\n",
    "\\end{equation}\n",
    "(where $M\\equiv 1$, so thats its $p(r)$ is normalized)\n",
    "and then\n",
    "\\begin{equation}\n",
    "P(v|r) = \\frac{F(r,v)}{p(r)} \\sim \\frac{v^{2}r^{2}\\left[-\\left(\\Phi(r)+\\frac{1}{2}v^{2}\\right)\\right]^{7/2}}{r^{2}\\left(1+\\frac{r^{2}}{a^{2}}\\right)^{5/2}}\n",
    "\\end{equation}\n",
    "However, any coefficient terms depending on r wont really matter since we're going to normalize it so we can ignore them.\n",
    "\\begin{equation}\n",
    "P(v|r)\\sim v^{2}\\left[-\\left(\\Phi(r)+\\frac{1}{2}v^{2}\\right)\\right]^{7/2}\n",
    "\\end{equation}\n",
    "In order to sample from this, it would be convenient if it was normalized.\n",
    "Here what people tend to do is to make another change of variables.\n",
    "We define $q\\equiv \\frac{v}{v_{\\rm esc}}$ where $v_{\\rm esc}$ is the escape velocity at $r$.\n",
    "since q can only be between 0 and 1, we can easily normalize it by integrating over the range of q.\n",
    "\n",
    "Ultimately we can write \n",
    "\\begin{equation}\n",
    "p(q|r) =\\frac{512}{7\\pi}q^2(1-q^2)^{7/2}\n",
    "\\end{equation}\n",
    "which *should* be easy to sample from. We've deceptible seemed to have gotten rid of the dependance of r, but we recover that dependance when we transform back via $v(r) = q~v_{\\rm esc}(r)$\n",
    "\n",
    "We still have a choice of sampling scheme here since the cdf is not analytically invertible. We can either use rejection sampling, or numerically calculate the cdf and extrapolate to get the inverse cdf, both work fine, rejection sampling works well enough for relatively large N, but the latter method might be better for very large N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
